{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV - MNIST classificaiton using CNN \n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)\n",
    "\n",
    "This notebook takes you through the implementation of image classification MNIST dataset using CNNs in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets \n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f80c4370af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train = datasets.MNIST('../../../data/computer_vision/mnist', train=True, download=True, transform=data_transform)\n",
    "\n",
    "test = datasets.MNIST('../../../data/computer_vision/mnist', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input-output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images (batch, channels, height, width):  torch.Size([64, 1, 28, 28])\n",
      "Output labels:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "print(\"Input images (batch, channels, height, width): \", images.size())\n",
    "print(\"Output labels: \", labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example image from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80bc4bd630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CNN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MnistClassifier, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(9*64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistClassifier(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout2d(p=0.1, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout2d(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout2d(p=0.2, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=576, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 7\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = MnistClassifier()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00: | Loss: 0.94244 | Acc: 0.74439\n",
      "Epoch 01: | Loss: 0.40810 | Acc: 0.88531\n",
      "Epoch 02: | Loss: 0.36491 | Acc: 0.89919\n",
      "Epoch 03: | Loss: 0.44363 | Acc: 0.88828\n",
      "Epoch 04: | Loss: 0.48069 | Acc: 0.87755\n",
      "Epoch 05: | Loss: 0.50695 | Acc: 0.87400\n",
      "Epoch 06: | Loss: 0.54101 | Acc: 0.86486\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        loss = criterion(y_pred_probs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        batch_acc = (y_pred == y_batch).sum().item()/BATCH_SIZE\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "    \n",
    "    print(f'Epoch {e+0:02}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = MnistClassifier()\n",
    "model.load_state_dict(torch.load(\"mnist\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        y_pred_probs = model(X_batch)\n",
    "        _, y_pred = torch.max(y_pred_probs, dim = 1)\n",
    "        \n",
    "        y_pred_list.append(y_pred.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       980\n",
      "           1       0.90      0.61      0.72      1135\n",
      "           2       0.87      0.87      0.87      1032\n",
      "           3       0.83      0.87      0.85      1010\n",
      "           4       0.85      0.90      0.88       982\n",
      "           5       0.85      0.88      0.86       892\n",
      "           6       0.96      0.82      0.89       958\n",
      "           7       0.93      0.87      0.90      1028\n",
      "           8       0.58      0.88      0.70       974\n",
      "           9       0.86      0.84      0.85      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.86      0.84      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
