{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Architecture Modules\n",
    "\n",
    "By [Akshaj Verma](https://akshajverma.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.rand(8, 64, 128, 128)\n",
    "\n",
    "input_tensor_batchsize = input_tensor.shape[0]\n",
    "input_tensor_channel = input_tensor.shape[1]\n",
    "input_tensor_size = input_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor batch size = 8\n",
      "Input tensor chanels = 64\n",
      "Input tensor size = (128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input tensor batch size = {input_tensor_batchsize}\")\n",
    "print(f\"Input tensor chanels = {input_tensor_channel}\")\n",
    "print(f\"Input tensor size = {input_tensor_size, input_tensor_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2016] Fire Module from SqueezeNet [[paper](https://arxiv.org/abs/1602.07360)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModule(nn.Module):\n",
    "    def __init__(self, c_in, c_out, channel_factor):\n",
    "        super(FireModule, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.channel_factor = channel_factor\n",
    "        \n",
    "        if self.c_in < self.channel_factor:\n",
    "            raise ValueError(\"Input channel cannot be less than or equal to channel factor.\")\n",
    "        \n",
    "        self.conv_squeeze_1x1 = self.conv_block(c_in=self.c_in, c_out=self.c_in//self.channel_factor, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_expand_1x1 = self.conv_block(c_in=self.c_in//self.channel_factor, c_out=self.c_in, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_expand_3x3 = self.conv_block(c_in=self.c_in//self.channel_factor, c_out=self.c_in, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv_expand_final = self.conv_block(c_in=2*self.c_in, c_out=self.c_out, kernel_size=1, stride=1, padding=0) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_squeeze_1x1(x)\n",
    "        \n",
    "        o1 = self.conv_expand_1x1(x)\n",
    "        o2 = self.conv_expand_3x3(x)\n",
    "        \n",
    "        cat = torch.cat((o1, o2), dim = 1)\n",
    "        out = self.conv_expand_final(cat)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def conv_block(self, c_in, c_out, **kwargs):\n",
    "        seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_module = FireModule(c_in = input_tensor_channel, c_out = input_tensor_channel, channel_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2017] MobileNet V1 [[paper](https://arxiv.org/abs/1704.04861)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilenetV1Module(nn.Module):\n",
    "    def __init__(self, c_in, c_out, is_downsample):\n",
    "        super(MobilenetV1Module, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.is_downsample = is_downsample\n",
    "        \n",
    "        self.conv_depthwise = self.depthwise_conv_block(c_in=self.c_in, c_out=self.c_in, is_downsample=self.is_downsample)\n",
    "        self.conv_1x1 = self.conv_1x1_block(c_in = self.c_in, c_out = self.c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_depthwise(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def depthwise_conv_block(self, c_in, c_out, is_downsample):\n",
    "        if is_downsample:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=2, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "                nn.ReLU6()\n",
    "            )\n",
    "        else:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=1, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "                nn.ReLU6()\n",
    "            )\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def conv_1x1_block(self, c_in, c_out):\n",
    "        seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1_module = MobilenetV1Module(c_in=input_tensor_channel, c_out=input_tensor_channel, is_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv1_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2018] MobileNet V2 [[paper](https://arxiv.org/abs/1801.04381)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilenetV2Module(nn.Module):\n",
    "    def __init__(self, c_in, c_out, channel_factor, is_downsample):\n",
    "        super(MobilenetV2Module, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        self.channel_factor = channel_factor\n",
    "        self.is_downsample = is_downsample\n",
    "        \n",
    "        self.conv_expansion = self.conv_1x1_block(c_in = self.c_in, c_out = self.c_in * self.channel_factor, is_linear=False)\n",
    "        \n",
    "        self.conv_depthwise = self.depthwise_conv_block(c_in=self.c_in * self.channel_factor, \n",
    "                                                        c_out=self.c_in * self.channel_factor, \n",
    "                                                        is_downsample=self.is_downsample)\n",
    "        \n",
    "        self.conv_projection = self.conv_1x1_block(c_in = self.c_in * self.channel_factor, c_out = self.c_out, is_linear=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.conv_expansion(x)\n",
    "        o = self.conv_depthwise(o)\n",
    "        o = self.conv_projection(o)\n",
    "        \n",
    "        if self.c_in == self.c_out and self.is_downsample is False:\n",
    "            o += x\n",
    "        \n",
    "        return o\n",
    "    \n",
    "    def depthwise_conv_block(self, c_in, c_out, is_downsample):\n",
    "        if is_downsample:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=2, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "                nn.ReLU6()\n",
    "            )\n",
    "        else:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=1, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "                nn.ReLU6()\n",
    "            )\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def conv_1x1_block(self, c_in, c_out, is_linear):\n",
    "        if is_linear:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "            )\n",
    "        else:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "                nn.ReLU6()\n",
    "            )\n",
    "         \n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2_module = MobilenetV2Module(c_in=input_tensor_channel, \n",
    "                                       c_out=input_tensor_channel, \n",
    "                                       channel_factor=2, \n",
    "                                       is_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenetv2_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2018] SqNext Module from SqueezeNext [[paper](https://arxiv.org/abs/1803.10615)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqNextModule(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(SqNextModule, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        self.conv_squeeze_1 = self.conv_block(c_in=self.c_in, c_out=self.c_in//2, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_squeeze_2 = self.conv_block(c_in=self.c_in//2, c_out=self.c_in//4, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.conv_1 = self.conv_block(c_in=self.c_in//4, c_out=self.c_in//2, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.conv_2 = self.conv_block(c_in=self.c_in//2, c_out=self.c_in//2, kernel_size=(3, 1), stride=1, padding=(1, 0))\n",
    "        \n",
    "        self.conv_expand = self.conv_block(c_in=self.c_in//2, c_out=self.c_out, kernel_size=1, stride=1, padding=0)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.conv_squeeze_1(x)\n",
    "        o = self.conv_squeeze_2(o)\n",
    "        o = self.conv_1(o)\n",
    "        o = self.conv_2(o)\n",
    "        o = self.conv_expand(o)\n",
    "        \n",
    "        if self.c_in == self.c_out:\n",
    "            o += x\n",
    "        \n",
    "        return o\n",
    "    \n",
    "    def conv_block(self, c_in, c_out, **kwargs):\n",
    "        seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqnext_module = SqNextModule(c_in=input_tensor_channel, c_out=input_tensor_channel*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 128, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqnext_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2018] ShuffleNetV2 [[paper](https://arxiv.org/abs/1807.11164)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShufflenetV2Module(nn.Module):\n",
    "    def __init__(self, c_in, channel_factor, is_downsample):\n",
    "        super(ShufflenetV2Module, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        \n",
    "        self.channel_factor = channel_factor\n",
    "        self.is_downsample = is_downsample\n",
    "        \n",
    "        if self.is_downsample is False:\n",
    "            self.conv_squeeze = self.conv_1x1_block(c_in = self.c_in//2, c_out=self.c_in//(2 * self.channel_factor))\n",
    "            self.conv_depth = self.depthwise_conv_block(c_in = self.c_in//(2 * self.channel_factor), \n",
    "                                                        c_out = self.c_in//(2 * self.channel_factor),\n",
    "                                                        is_downsample = self.is_downsample\n",
    "                                                       )\n",
    "            self.conv_expand = self.conv_1x1_block(c_in = self.c_in//(2 * self.channel_factor), c_out= self.c_in//2)\n",
    "        else:\n",
    "            # right\n",
    "            self.conv_squeeze = self.conv_1x1_block(c_in = self.c_in, c_out=self.c_in//(self.channel_factor))\n",
    "            self.conv_depth_1 = self.depthwise_conv_block(c_in = self.c_in//( self.channel_factor), \n",
    "                                                        c_out = self.c_in//(self.channel_factor),\n",
    "                                                        is_downsample = self.is_downsample\n",
    "                                                       )\n",
    "            self.conv_expand = self.conv_1x1_block(c_in = self.c_in//(self.channel_factor), c_out= self.c_in)\n",
    "            \n",
    "            # left\n",
    "            self.conv_depth_2 = self.depthwise_conv_block(c_in = self.c_in, \n",
    "                                                        c_out = self.c_in,\n",
    "                                                        is_downsample = self.is_downsample\n",
    "                                                       )\n",
    "            self.conv_1x1 = self.conv_1x1_block(c_in = self.c_in, c_out= self.c_in)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.is_downsample is False:\n",
    "            x1, x2 = torch.split(x, split_size_or_sections=self.c_in//2, dim=1)\n",
    "            \n",
    "            x2 = self.conv_squeeze(x2)\n",
    "            x2 = self.conv_depth(x2)\n",
    "            x2 = self.conv_expand(x2)\n",
    "            \n",
    "            o = torch.cat((x1, x2), dim=1)\n",
    "            o = o[:][torch.randperm(o.shape[0])][:, :]\n",
    "            \n",
    "        else:\n",
    "            x1 = self.conv_squeeze(x)\n",
    "            x1 = self.conv_depth_1(x1)\n",
    "            x1 = self.conv_expand(x1)\n",
    "            \n",
    "            x2 = self.conv_depth_2(x)\n",
    "            x2 = self.conv_1x1(x2)\n",
    "            \n",
    "            o = torch.cat((x1, x2), dim =1)\n",
    "            o = o[:][torch.randperm(o.shape[0])][:, :]\n",
    "\n",
    "        return o\n",
    "        \n",
    "    def depthwise_conv_block(self, c_in, c_out, is_downsample):\n",
    "        if is_downsample:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=2, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "            )\n",
    "        else:\n",
    "            seq = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=3, stride=1, padding=1, groups=c_in),\n",
    "                nn.BatchNorm2d(num_features=c_out),\n",
    "            )\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def conv_1x1_block(self, c_in, c_out):\n",
    "        seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shufflenetv2_module = ShufflenetV2Module(c_in=input_tensor_channel, channel_factor=2, is_downsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 64, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shufflenetv2_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2019] MobileNet V3 [[paper](https://arxiv.org/abs/1905.02244)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilenetV3Module(nn.Module):\n",
    "    def __init__(self, c_in, c_out, channel_factor):\n",
    "        super(MobilenetV3Module, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        self.channel_factor = channel_factor\n",
    "        \n",
    "        self.conv_first = nn.Conv2d(in_channels=self.c_in, out_channels=self.c_in, kernel_size=3, stride=1, padding=1)\n",
    "        self.depth_conv = nn.Conv2d(in_channels=self.c_in, out_channels=self.c_in, kernel_size=3, stride=1, padding=1, groups=self.c_in)\n",
    "        \n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        self.conv_excitation_downsample = nn.Conv2d(in_channels=self.c_in, \n",
    "                                               out_channels=self.c_in//self.channel_factor, \n",
    "                                               kernel_size=1, \n",
    "                                               stride=1, \n",
    "                                               padding=0)\n",
    "        \n",
    "        self.conv_excitation_upsample = nn.Conv2d(in_channels=self.c_in//self.channel_factor, \n",
    "                                             out_channels=self.c_in, \n",
    "                                             kernel_size=1, \n",
    "                                             stride=1, \n",
    "                                             padding=0)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(in_channels=self.c_in, out_channels=self.c_out, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        \n",
    "        self.hswish = nn.Hardswish()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.relu6 = nn.ReLU6()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hswish(self.conv_first(x))\n",
    "        x = self.hswish(self.depth_conv(x))\n",
    "        \n",
    "        o = self.squeeze(x)\n",
    "        \n",
    "        o = self.relu(self.conv_excitation_downsample(o))\n",
    "        o = self.relu6(self.conv_excitation_upsample(o))\n",
    "        \n",
    "\n",
    "        x *= o\n",
    "        x = self.conv_last(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilnetv3_module = MobilenetV3Module(c_in=input_tensor_channel, c_out=input_tensor_channel, channel_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilnetv3_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2019] GhostModule from GhostNet [[paper](https://arxiv.org/abs/1911.11907)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.c_in = c_in\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.c_in, \n",
    "                              out_channels=self.c_in//2,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1)\n",
    "        \n",
    "        self.conv_depth = nn.Conv2d(in_channels=self.c_in//2, \n",
    "                                    out_channels=self.c_in//2, \n",
    "                                    kernel_size=3, \n",
    "                                    stride=1, \n",
    "                                    padding=1, \n",
    "                                    groups=self.c_in//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        o = self.conv_depth(x)\n",
    "        output = torch.cat((x, o), dim = 1)\n",
    "        \n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_module = GhostModule(c_in=input_tensor_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghost_module(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fire(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        squeeze_planes: int,\n",
    "        expand1x1_planes: int,\n",
    "        expand3x3_planes: int\n",
    "    ) -> None:\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "\n",
    "class SqueezeNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        version: str = '1_0',\n",
    "        num_classes: int = 1000\n",
    "    ) -> None:\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(64, 16, 64, 64),\n",
    "            Fire(128, 16, 64, 64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(128, 32, 128, 128),\n",
    "            Fire(256, 32, 128, 128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(256, 48, 192, 192),\n",
    "            Fire(384, 48, 192, 192),\n",
    "            Fire(384, 64, 256, 256),\n",
    "            Fire(512, 64, 256, 256),\n",
    "        )\n",
    "    \n",
    "        # Final convolution is initialized differently from the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is final_conv:\n",
    "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
